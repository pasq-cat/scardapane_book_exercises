{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5 exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pytorch implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images batch shape: torch.Size([64, 1, 28, 28])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define transformations for the dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "\n",
    "# Load the MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = MNIST(root='./data/mnist', train=True, download=True, transform=transform)\n",
    "val_dataset = MNIST(root='./data/mnist', train=False, download=True, transform=transform)\n",
    "\n",
    "# Define the DataLoader\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Iterate through the DataLoader\n",
    "for images, labels in train_loader:\n",
    "    print(f'Images batch shape: {images.size()}')\n",
    "    print(f'Labels batch shape: {labels.size()}')\n",
    "    break  # Just to demonstrate, break after the first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomLayer(\n",
      "  (linear): Linear(in_features=784, out_features=128, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define a custom layer\n",
    "class CustomLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features, activation):\n",
    "        super(CustomLayer, self).__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate and test the custom layer\n",
    "custom_layer = CustomLayer(28 * 28, 128, F.relu)\n",
    "print(custom_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomNN(\n",
      "  (layer1): CustomLayer(\n",
      "    (linear): Linear(in_features=784, out_features=128, bias=True)\n",
      "  )\n",
      "  (layer2): CustomLayer(\n",
      "    (linear): Linear(in_features=128, out_features=64, bias=True)\n",
      "  )\n",
      "  (output_layer): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define a custom neural network using the custom layer\n",
    "class CustomNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomNN, self).__init__()\n",
    "        self.layer1 = CustomLayer(28 * 28, 128, F.relu)\n",
    "        self.layer2 = CustomLayer(128, 64, F.relu)\n",
    "        self.output_layer = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)  # Flatten the input tensor\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate and test the custom neural network\n",
    "model = CustomNN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.3500\n",
      "Validation Accuracy: 94.96%\n",
      "Epoch [2/5], Loss: 0.1389\n",
      "Validation Accuracy: 96.11%\n",
      "Epoch [3/5], Loss: 0.0945\n",
      "Validation Accuracy: 96.81%\n",
      "Epoch [4/5], Loss: 0.0725\n",
      "Validation Accuracy: 97.12%\n",
      "Epoch [5/5], Loss: 0.0568\n",
      "Validation Accuracy: 97.15%\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()  # Zero the parameter gradients\n",
    "        outputs = model(images)  # Forward pass\n",
    "        loss = criterion(outputs, labels)  # Compute the loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Update the parameters\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Validation Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## jax implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.1374, Accuracy: 0.9604\n",
      "Epoch [2/5], Loss: 0.1015, Accuracy: 0.9689\n",
      "Epoch [3/5], Loss: 0.0790, Accuracy: 0.9749\n",
      "Epoch [4/5], Loss: 0.0772, Accuracy: 0.9775\n",
      "Epoch [5/5], Loss: 0.0755, Accuracy: 0.9766\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "from jax import random, grad, jit, vmap\n",
    "from jax.nn import relu, log_softmax\n",
    "from jax.scipy.special import logsumexp\n",
    "\n",
    "# Define the neural network\n",
    "def init_params(key):\n",
    "    keys = random.split(key, 3)\n",
    "    params = {\n",
    "        'W1': random.normal(keys[0], (28 * 28, 128)) * jnp.sqrt(2.0 / (28 * 28)), #kaiming initialization\n",
    "        'b1': jnp.zeros(128),\n",
    "        'W2': random.normal(keys[1], (128, 64)) * jnp.sqrt(2.0 / 128),\n",
    "        'b2': jnp.zeros(64),\n",
    "        'W3': random.normal(keys[2], (64, 10)) * jnp.sqrt(2.0 / 64),\n",
    "        'b3': jnp.zeros(10)\n",
    "    }\n",
    "    return params\n",
    "\n",
    "def forward(params, x):\n",
    "    x = x.reshape(-1, 28 * 28)  # Flatten the input tensor\n",
    "    x = relu(jnp.dot(x, params['W1']) + params['b1'])\n",
    "    x = relu(jnp.dot(x, params['W2']) + params['b2'])\n",
    "    x = jnp.dot(x, params['W3']) + params['b3']\n",
    "    return x\n",
    "\n",
    "# Define the loss function\n",
    "def cross_entropy_loss(logits, labels):\n",
    "    one_hot_labels = jax.nn.one_hot(labels, num_classes=10)\n",
    "    return -jnp.mean(jnp.sum(one_hot_labels * log_softmax(logits), axis=-1))\n",
    "\n",
    "# Define the accuracy function\n",
    "def accuracy(logits, labels):\n",
    "    predictions = jnp.argmax(logits, axis=-1)\n",
    "    return jnp.mean(predictions == labels)\n",
    "\n",
    "# Define the training step\n",
    "@jit\n",
    "def train_step(params, opt_state, images, labels):\n",
    "    def loss_fn(params):\n",
    "        logits = forward(params, images)\n",
    "        loss = cross_entropy_loss(logits, labels)\n",
    "        return loss\n",
    "\n",
    "    grads = grad(loss_fn)(params)\n",
    "    updates, opt_state = optimizer.update(grads, opt_state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    return params, opt_state\n",
    "\n",
    "# Initialize the model and optimizer\n",
    "key = random.PRNGKey(0)\n",
    "params = init_params(key)\n",
    "optimizer = optax.adam(learning_rate=0.001)\n",
    "opt_state = optimizer.init(params)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "batch_size = 64\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Assuming train_loader is an iterable of (images, labels) batches\n",
    "    for images, labels in train_loader:\n",
    "        images = jnp.array(images.numpy())\n",
    "        labels = jnp.array(labels.numpy())\n",
    "        params, opt_state = train_step(params, opt_state, images, labels)\n",
    "\n",
    "    # Compute training loss and accuracy\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    num_batches = 0\n",
    "    for images, labels in val_loader:\n",
    "        images = jnp.array(images.numpy())\n",
    "        labels = jnp.array(labels.numpy())\n",
    "        logits = forward(params, images)\n",
    "        train_loss += cross_entropy_loss(logits, labels)\n",
    "        train_acc += accuracy(logits, labels)\n",
    "        num_batches += 1\n",
    "\n",
    "    train_loss /= num_batches\n",
    "    train_acc /= num_batches\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images_with_predictions(images, predictions, true_labels):\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(8, 8))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for img, pred, true_label, ax in zip(images, predictions, true_labels, axes):\n",
    "        ax.imshow(img.squeeze(), cmap='gray')\n",
    "        ax.set_title(f'Pred: {pred}, True: {true_label}')\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get batch of data\n",
    "images, labels = next(iter(val_loader))\n",
    "#convert to jax array\n",
    "images = jnp.array(images.numpy())\n",
    "labels = jnp.array(labels.numpy())\n",
    "# make predictions\n",
    "logits = forward(params, images)\n",
    "predictions = jnp.argmax(logits, axis=-1)\n",
    "#extract 9 images\n",
    "images_9 = images[:9]\n",
    "predictions_9 = predictions[:9]\n",
    "labels_9 = labels[:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_images_with_predictions(images_9, predictions_9, labels_9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jax with Equinox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equinox allows us to use Jax with a pytorch like syntax based on classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import equinox as eqx\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax  # https://github.com/deepmind/optax\n",
    "import torch  # https://pytorch.org\n",
    "import torchvision  # https://pytorch.org\n",
    "from jaxtyping import Array, Float, Int, PyTree  # https://github.com/google/jaxtyping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 3e-4\n",
    "STEPS = 300\n",
    "PRINT_EVERY = 30\n",
    "SEED = 5678\n",
    "\n",
    "key = jax.random.PRNGKey(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class equi_model(eqx.Module):\n",
    "    layers: list\n",
    "\n",
    "    def __init__(self, key):\n",
    "        key1, key2, key3, key4 = jax.random.split(key, 4)\n",
    "        # Standard CNN setup: convolutional layer, followed by flattening,\n",
    "        # with a small MLP on top.\n",
    "        self.layers = [\n",
    "            eqx.nn.Linear(28*28, 128, key=key3),\n",
    "            jax.nn.relu,\n",
    "            eqx.nn.Linear(128, 64, key=key3),\n",
    "            jax.nn.relu,\n",
    "            eqx.nn.Linear(64, 10, key=key4),\n",
    "        ]\n",
    "\n",
    "    def __call__(self, x: Float[Array, \"1 28 28\"]) -> Float[Array, \"10\"]:\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "key, subkey = jax.random.split(key, 2)\n",
    "model = equi_model(subkey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(\n",
    "    model: equi_model, x: Float[Array, \"batch 1 28 28\"], y: Int[Array, \" batch\"]\n",
    ") -> Float[Array, \"\"]:\n",
    "    # Our input has the shape (BATCH_SIZE, 1, 28, 28), but our model operations on\n",
    "    # a single input input image of shape (1, 28, 28).\n",
    "    #\n",
    "    # Therefore, we have to use jax.vmap, which in this case maps our model over the\n",
    "    # leading (batch) axis.\n",
    "    pred_y = jax.vmap(model)(x)\n",
    "    return cross_entropy(y, pred_y)\n",
    "\n",
    "\n",
    "def cross_entropy(\n",
    "    y: Int[Array, \" batch\"], pred_y: Float[Array, \"batch\"]\n",
    ") -> Float[Array, \"\"]:\n",
    "    # y are the true targets, and should be integers 0-9.\n",
    "    # pred_y are the logits  predictions.\n",
    "    labels_onehot = jax.nn.one_hot(labels, num_classes=10)\n",
    "    return optax.softmax_cross_entropy(logits=logits, labels=labels_onehot).mean()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = eqx.filter_jit(loss)  # JIT our loss function from earlier!\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def compute_accuracy(\n",
    "    model: equi_model, x: Float[Array, \"batch 1 28 28\"], y: Int[Array, \" batch\"]\n",
    ") -> Float[Array, \"\"]:\n",
    "    \"\"\"This function takes as input the current model\n",
    "    and computes the average accuracy on a batch.\n",
    "    \"\"\"\n",
    "    pred_y = jax.vmap(model)(x)\n",
    "    pred_y = jnp.argmax(pred_y, axis=1)\n",
    "    return jnp.mean(y == pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model: equi_model, val_loader: torch.utils.data.DataLoader):\n",
    "    \"\"\"This function evaluates the model on the test dataset,\n",
    "    computing both the average loss and the average accuracy.\n",
    "    \"\"\"\n",
    "    avg_loss = 0\n",
    "    avg_acc = 0\n",
    "    for x, y in val_loader:\n",
    "        x = x.numpy()\n",
    "        y = y.numpy()\n",
    "        # Note that all the JAX operations happen inside `loss` and `compute_accuracy`,\n",
    "        # and both have JIT wrappers, so this is fast.\n",
    "        avg_loss += loss(model, x, y)\n",
    "        avg_acc += compute_accuracy(model, x, y)\n",
    "    return avg_loss / len(val_loader), avg_acc / len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = optax.adamw(LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: equi_model,\n",
    "    trainloader: torch.utils.data.DataLoader,\n",
    "    testloader: torch.utils.data.DataLoader,\n",
    "    optim: optax.GradientTransformation,\n",
    "    steps: int,\n",
    "    print_every: int,\n",
    ") -> equi_model:\n",
    "    # Just like earlier: It only makes sense to train the arrays in our model,\n",
    "    # so filter out everything else.\n",
    "    opt_state = optim.init(eqx.filter(model, eqx.is_array))\n",
    "\n",
    "    # Always wrap everything -- computing gradients, running the optimiser, updating\n",
    "    # the model -- into a single JIT region. This ensures things run as fast as\n",
    "    # possible.\n",
    "    @eqx.filter_jit\n",
    "    def make_step(\n",
    "        model: equi_model,\n",
    "        opt_state: PyTree,\n",
    "        x: Float[Array, \"batch 1 28 28\"],\n",
    "        y: Int[Array, \" batch\"],\n",
    "    ):\n",
    "        loss_value, grads = eqx.filter_value_and_grad(loss)(model, x, y)           \n",
    "        updates, opt_state = optim.update(grads, opt_state, model)\n",
    "        model = eqx.apply_updates(model, updates)\n",
    "        return model, opt_state, loss_value\n",
    "\n",
    "    # Loop over our training dataset as many times as we need.\n",
    "    def infinite_trainloader():\n",
    "        while True:\n",
    "            yield from trainloader\n",
    "\n",
    "    for step, (x, y) in zip(range(steps), infinite_trainloader()):\n",
    "        # PyTorch dataloaders give PyTorch tensors by default,\n",
    "        # so convert them to NumPy arrays.\n",
    "        x = x.numpy()\n",
    "        y = y.numpy()\n",
    "        model, opt_state, train_loss = make_step(model, opt_state, x, y)\n",
    "        if (step % print_every) == 0 or (step == steps - 1):\n",
    "            test_loss, test_accuracy = evaluate(model, testloader)\n",
    "            print(\n",
    "                f\"{step=}, train_loss={train_loss.item()}, \"\n",
    "                f\"test_loss={test_loss.item()}, test_accuracy={test_accuracy.item()}\"\n",
    "            )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "dot_general requires contracting dimensions to have the same shape, got (784,) and (28,).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSTEPS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPRINT_EVERY\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[26], line 38\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, trainloader, testloader, optim, steps, print_every)\u001b[0m\n\u001b[0;32m     36\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     37\u001b[0m y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m---> 38\u001b[0m model, opt_state, train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mmake_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (step \u001b[38;5;241m%\u001b[39m print_every) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (step \u001b[38;5;241m==\u001b[39m steps \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     40\u001b[0m     test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m evaluate(model, testloader)\n",
      "    \u001b[1;31m[... skipping hidden 15 frame]\u001b[0m\n",
      "Cell \u001b[1;32mIn[26], line 23\u001b[0m, in \u001b[0;36mtrain.<locals>.make_step\u001b[1;34m(model, opt_state, x, y)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;129m@eqx\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_jit\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_step\u001b[39m(\n\u001b[0;32m     18\u001b[0m     model: equi_model,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m     y: Int[Array, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m batch\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     22\u001b[0m ):\n\u001b[1;32m---> 23\u001b[0m     loss_value, grads \u001b[38;5;241m=\u001b[39m \u001b[43meqx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter_value_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m           \n\u001b[0;32m     24\u001b[0m     updates, opt_state \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mupdate(grads, opt_state, model)\n\u001b[0;32m     25\u001b[0m     model \u001b[38;5;241m=\u001b[39m eqx\u001b[38;5;241m.\u001b[39mapply_updates(model, updates)\n",
      "    \u001b[1;31m[... skipping hidden 25 frame]\u001b[0m\n",
      "Cell \u001b[1;32mIn[22], line 9\u001b[0m, in \u001b[0;36mloss\u001b[1;34m(model, x, y)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss\u001b[39m(\n\u001b[0;32m      2\u001b[0m     model: equi_model, x: Float[Array, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch 1 28 28\u001b[39m\u001b[38;5;124m\"\u001b[39m], y: Int[Array, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m batch\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      3\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Float[Array, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Therefore, we have to use jax.vmap, which in this case maps our model over the\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# leading (batch) axis.\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     pred_y \u001b[38;5;241m=\u001b[39m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cross_entropy(y, pred_y)\n",
      "    \u001b[1;31m[... skipping hidden 3 frame]\u001b[0m\n",
      "Cell \u001b[1;32mIn[14], line 18\u001b[0m, in \u001b[0;36mequi_model.__call__\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Float[Array, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1 28 28\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Float[Array, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m10\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 18\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32md:\\Users\\Pasqu\\anaconda3\\envs\\scardapane-alice\\Lib\\contextlib.py:81\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[1;32m---> 81\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Users\\Pasqu\\anaconda3\\envs\\scardapane-alice\\Lib\\site-packages\\equinox\\nn\\_linear.py:95\u001b[0m, in \u001b[0;36mLinear.__call__\u001b[1;34m(self, x, key)\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx must have scalar shape\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     94\u001b[0m     x \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mbroadcast_to(x, (\u001b[38;5;241m1\u001b[39m,))\n\u001b[1;32m---> 95\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     97\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\n",
      "File \u001b[1;32md:\\Users\\Pasqu\\anaconda3\\envs\\scardapane-alice\\Lib\\site-packages\\jax\\_src\\numpy\\array_methods.py:1036\u001b[0m, in \u001b[0;36m_forward_operator_to_aval.<locals>.op\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mop\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m-> 1036\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Users\\Pasqu\\anaconda3\\envs\\scardapane-alice\\Lib\\site-packages\\jax\\_src\\numpy\\array_methods.py:573\u001b[0m, in \u001b[0;36m_defer_to_unrecognized_arg.<locals>.deferring_binary_op\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    571\u001b[0m args \u001b[38;5;241m=\u001b[39m (other, \u001b[38;5;28mself\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m swap \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28mself\u001b[39m, other)\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, _accepted_binop_types):\n\u001b[1;32m--> 573\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[38;5;66;03m# Note: don't use isinstance here, because we don't want to raise for\u001b[39;00m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;66;03m# subclasses, e.g. NamedTuple objects that may override operators.\u001b[39;00m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(other) \u001b[38;5;129;01min\u001b[39;00m _rejected_binop_types:\n",
      "    \u001b[1;31m[... skipping hidden 11 frame]\u001b[0m\n",
      "File \u001b[1;32md:\\Users\\Pasqu\\anaconda3\\envs\\scardapane-alice\\Lib\\site-packages\\jax\\_src\\numpy\\lax_numpy.py:8216\u001b[0m, in \u001b[0;36mmatmul\u001b[1;34m(a, b, precision, preferred_element_type)\u001b[0m\n\u001b[0;32m   8214\u001b[0m a \u001b[38;5;241m=\u001b[39m lax\u001b[38;5;241m.\u001b[39msqueeze(a, \u001b[38;5;28mtuple\u001b[39m(a_squeeze))\n\u001b[0;32m   8215\u001b[0m b \u001b[38;5;241m=\u001b[39m lax\u001b[38;5;241m.\u001b[39msqueeze(b, \u001b[38;5;28mtuple\u001b[39m(b_squeeze))\n\u001b[1;32m-> 8216\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mlax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot_general\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   8217\u001b[0m \u001b[43m  \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mndim\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mndim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb_is_mat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43ma_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_batch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8218\u001b[0m \u001b[43m  \u001b[49m\u001b[43mprecision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreferred_element_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreferred_element_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   8219\u001b[0m result \u001b[38;5;241m=\u001b[39m lax\u001b[38;5;241m.\u001b[39mtranspose(out, perm)\n\u001b[0;32m   8220\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m lax_internal\u001b[38;5;241m.\u001b[39m_convert_element_type(result, preferred_element_type, output_weak_type)\n",
      "    \u001b[1;31m[... skipping hidden 7 frame]\u001b[0m\n",
      "File \u001b[1;32md:\\Users\\Pasqu\\anaconda3\\envs\\scardapane-alice\\Lib\\site-packages\\jax\\_src\\lax\\lax.py:3117\u001b[0m, in \u001b[0;36m_dot_general_shape_rule\u001b[1;34m(lhs, rhs, dimension_numbers, precision, preferred_element_type, algorithm, transpose_algorithm)\u001b[0m\n\u001b[0;32m   3114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m core\u001b[38;5;241m.\u001b[39mdefinitely_equal_shape(lhs_contracting_shape, rhs_contracting_shape):\n\u001b[0;32m   3115\u001b[0m   msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdot_general requires contracting dimensions to have the same \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3116\u001b[0m          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 3117\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(lhs_contracting_shape, rhs_contracting_shape))\n\u001b[0;32m   3119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _dot_general_shape_computation(lhs\u001b[38;5;241m.\u001b[39mshape, rhs\u001b[38;5;241m.\u001b[39mshape, dimension_numbers)\n",
      "\u001b[1;31mTypeError\u001b[0m: dot_general requires contracting dimensions to have the same shape, got (784,) and (28,)."
     ]
    }
   ],
   "source": [
    "model = train(model, train_loader, val_loader, optim, STEPS, PRINT_EVERY)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scardapane-alice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
